:toc:

= Virtualization with Relational Database [[rdbms-example]]

This example gives necessary guideline as to how to develop and deploy a virtualization using a single relational database (Postgresql).

== Prerequisites

==== Access to OpenShift
Log into your OpenShift instance using `oc login` command. If you do not have already access to a OpenShift instance, you can install a local `minishift` instance following these xref:../minishift.adoc[directions] 

==== Install or subscribe to the Teiid/DV Operator 

Once the OpenShift is available then install the Operator from OperatorHub or the directions from xref:../install-operator.adoc[here]

Learn basics of "DV on Openshift" xref:../dv-on-openshift.adoc[here] before you proceed.

==== Set up a PostgreSQL Database (Testing Purpose Only)
If you already have a database running on your network, then gather credentials to access that data source. Otherwise execute following scripts to create a PostgreSQL database on the OpenShift instance.

[source,bash]
----
# DEPLOY POSTGRES DATABASE
oc new-app \
  -e POSTGRESQL_USER=user \
  -e POSTGRESQL_PASSWORD=mypassword \
  -e POSTGRESQL_DATABASE=sampledb \
  postgresql:9.5

# CREATE SECRET TO CONNECT TO DATABASE (ADJUST TO YOUR VALUES)
oc create -f - <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: postgresql
type: Opaque
stringData:
  database-user: user
  database-name: sampledb
  database-password: mypassword
EOF
----

Now, that the database is created find the OpenShift pod created for this database using

[source,bash]
----
oc get pods 
----

Find the pod starting with `postgres-xxxxx` and then connect to by executing

[source,bash]
----
# connect using remote shell
oc rsh postgres-xxxxx

# this will be shown
sh-4.2$

# use psql to connect to database and create some tables
sh-4.2$ psql -U user sampledb
----

And at the prompt add in the following schema

[source,sql]
----
CREATE TABLE CUSTOMER
(
   ID bigint,
   SSN char(25),
   NAME varchar(64),
   CONSTRAINT CUSTOMER_PK PRIMARY KEY(ID)
);

CREATE TABLE ADDRESS
(
   ID bigint,
   STREET char(25),
   ZIP char(10),
   CUSTOMER_ID bigint,
   CONSTRAINT ADDRESS_PK PRIMARY KEY(ID),
   CONSTRAINT CUSTOMER_FK FOREIGN KEY (CUSTOMER_ID) REFERENCES CUSTOMER (ID)
);

INSERT INTO CUSTOMER (ID,SSN,NAME) VALUES (10, 'CST01002','Joseph Smith');
INSERT INTO CUSTOMER (ID,SSN,NAME) VALUES (11, 'CST01003','Nicholas Ferguson');
INSERT INTO CUSTOMER (ID,SSN,NAME) VALUES (12, 'CST01004','Jane Aire');
INSERT INTO ADDRESS (ID, STREET, ZIP, CUSTOMER_ID) VALUES (10, 'Main St', '12345', 10);
----

Database is setup now.

== Development of a Virtualization

A user can develop a Virtualization a few different ways. Each of the options have advantages and disadvantages. In the end all options use the Operator to deploy the Virtualization to OpenShift and yield _exactly same_ virtualization runtime with the same features. The choice depends upon the complexity of the project and the need for testing on and off the OpenShift platform.  

NOTE: Each option shows the *same* example with different ways of development.

=== Directly Using the Operator
Using this option user can directly define the VDB contents in the form of DDL in the `Custom Resource` file directly and use the Operator to deploy this virtualization. When deployed, the Operator will put together S2I build on OpenShift based dependencies it can glean from the VDB artifact. This may fail if certain dependencies are not found - like if the developer omits the dependencies of JDBC drivers, etc.

===== Pros
* Simple and minimalistic
* All the code and configuration related to this virtualization is in single file. 
* The management becomes really easy. 

===== Cons
* `Custom Resource` file can get large with amount of DDL.
* VDB is embedded in `Custom Resource`
* More difficult to version the VDB independently.
* When working with multiple environments, need to move properties to config-maps or secrets to be independent of the `Custom Resource`

Find an example for this in `vdb-in-operator` folder, with xref:vdb-in-operator/Readme.adoc[Readme here].

=== Using Maven Project
Using Maven project option user can define a virtualization file (VDB) *"as part of"* a maven based Java project. The VDB is defined as resource file and the `pom.xml` defines required dependencies to build this into a Spring Boot Java executable. User can use this executable locally to test. In the end, the user is expected to commit this working project to a GIT repository, and use the GIT repository location as source of build in the `Custom Resource` for the Operator.

Any data source configuration is defined as part of Operator's `Custom Resource` file. When deployed, Operator will do S2I build using the above mentioned GIT repository, no introspection of the VDB is done in this step, it is expected user has provided all the required dependencies.

==== Pros
* Clean separation of DDL code that represents the VDB and Configuration.
* Local testing of the virtualization without OpenShift. Note: caching, authentication, that is environmentally dependent on OpenShift will not work locally.
* Any extensions like UDF, custom translators, etc. can be included as part of the project and they will be folded into runtime automatically.
* Suitable for deployment into multiple environments.
* Versioning is done at the level of the overall project.

==== Cons
* User is required to have the Maven working knowledge. To provide an extension knowledge of Java development is required. 

Find an example for this in `vdb-in-maven` folder, with xref:vdb-in-maven/Readme.adoc[Readme here].


=== Using Virtualization as Maven Artifact
Using this option one can define a virtualization *as* a maven artifact. Basically instead of providing DDL file as Virtualization, you can provide a particular Maven artifact as a Virtualization.

Teiid provides tools in the form of Maven plugins to convert a given DDL file into a maven artifact. The DDL file(s) are converted that into a Maven artifact that can be pushed to a maven repository with a given version defined in your `pom.xml` file. 

Then this artifact can be deployed directly using the Operator. For deployment of the virtualization one need use either of above options in concert with this. This only creates virtualization as maven artifact.

This is an advanced option.  However it may be suitable for projects with some level of complexity, as this provides the most flexible options. Typically this is developed as a multi-module maven project, with vdb sharing using the `vdb-import` feature.

==== Pros
* Flexible, clean separation of DDL code that represents the VDB and configuration.
* Suitable for deployment into multiple environments.
* Versioning is done at the VDB level.
* A must have when using the `vdb-import` feature to import this VDB into other vdbs.
* Virtualization can be sharable with other projects and other teams in a consistent way.
* Consistent with CI/CD workflows.

==== Cons
* User is required to have the Maven working knowledge.
* Relatively complex.

Find an example for this in `vdb-as-maven-artifact` folder, with xref:vdb-as-maven-artifact/Readme.adoc[Readme here].

== Deployment of Virtualization

Deployment of the virtualization is *always* done using the Operator. However, how the `Custom Resource` is defined for the deployment of virtualization depends upon the type of development model used. Each of the methods define how the Virtualizations can be deployed in their respective sections.

== Accessing the deployed Virtualization [vdb-access]
One virtualization is deployed in the OpenShift, it can be accessed using JDBC/ODBC and with variety of PostgreSQL clients along with OData.  We'll focus only on JDBC access via a Java client here.

=== JDBC Connection From Client In OpenShift

If you want to use JDBC to connect to your virtual databases. You can use this link:https://oss.sonatype.org/service/local/repositories/releases/content/org/teiid/teiid/12.3.0/teiid-12.3.0-jdbc.jar[JDBC Driver]. If you would like to use it in your application, then include the maven dependency with the appropriate version:

[source,xml]
----
<dependency>
  <groupId>org.teiid</groupId>
  <artifactId>teiid</artifactId>
  <classifier>jdbc</classifier>
  <version>${version.teiid}</version>
</dependency>
----

To connect to the database, use the following:

URL: `jdbc:teiid:customer@mm://dv-customer.myproject.svc:31000`

JDBC Class: `org.teiid.jdbc.TeiidDriver`

JDBC Driver: `teiid-12.3.0-jdbc.jar`

As this example does not use authentication, no credentials are needed.

=== JDBC Connection From External Client 

JDBC is not exposed to outside applications by default - there is only an internal service created.

If you have an external application that is using JDBC or the Postgres protocol issue the following:

[source,yaml]
----
$oc create -f - <<INGRESS
apiVersion: v1
kind: Service
metadata:
  name: dv-customer-ingress
spec:
  ports:
  - name: teiid
    port: 31000
  type: LoadBalancer 
  selector:
    app: dv-customer
  sessionAffinity: ClientIP
INGRESS
----

To determine the ip/port run: 

[source,bash]
----
$oc get svc dv-customer-ingress
----

NOTE: The above INGRESS may not be possible with public OpenShift instances as it requires opening a port.
